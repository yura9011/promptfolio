# Agent Discipline Protocol

## The Problem

AI agents (ChatGPT, Claude, Kiro, etc.) can "go rogue" and:
- Invent their own plans instead of following IMPLEMENTATION_PLAN.md
- Start working without reading context files
- Make assumptions about what needs to be done
- Ignore the Ralph Loop protocol

This happens because:
1. Agents are trained to be helpful and autonomous
2. They assume they should start working immediately
3. They don't know about project-specific workflows
4. Context transfer can lose critical instructions

## Universal Solution (No IDE Dependencies)

Since GSD Universal works with ANY AI in ANY environment, we can't rely on:
- IDE-specific hooks
- Steering files (Kiro-only)
- Custom system prompts
- Automated enforcement

Instead, we use **three layers of defense**:

### Layer 1: AGENTS.md (Always Included)

`AGENTS.md` is the first file agents see. It MUST say:

```markdown
## CRITICAL: Read IMPLEMENTATION_PLAN.md FIRST

BEFORE doing ANY work:
1. Read IMPLEMENTATION_PLAN.md
2. Execute ONLY the next pending task
3. Update IMPLEMENTATION_PLAN.md after
4. DO NOT invent your own plan
```

This is at the TOP of AGENTS.md, impossible to miss.

### Layer 2: PROMPT Files (Explicit Instructions)

`PROMPT_build.md` and `PROMPT_plan.md` start with:

```markdown
## CRITICAL FIRST STEP

STOP. Before doing ANYTHING:
1. Read IMPLEMENTATION_PLAN.md
2. Find the next pending task
3. Execute ONLY that task
4. Update IMPLEMENTATION_PLAN.md

DO NOT:
- Start without reading IMPLEMENTATION_PLAN.md
- Invent your own plan
- Work on multiple tasks
```

These prompts are generated by `ralph.ps1`/`ralph.sh` scripts.

### Layer 3: User Discipline

The USER must:
1. **Use the scripts**: Run `./scripts/ralph.ps1 -Mode build` instead of asking directly
2. **Copy the full prompt**: Don't paraphrase or summarize
3. **Verify first action**: Check that agent reads IMPLEMENTATION_PLAN.md first
4. **Interrupt if wrong**: Stop agent if it starts inventing plans

## What to Do When Agent Goes Rogue

If an agent starts working without reading IMPLEMENTATION_PLAN.md:

### Immediate Action

```
STOP. You are not following the Ralph Loop protocol.

1. Read IMPLEMENTATION_PLAN.md NOW
2. Show me what tasks are pending
3. Confirm which task you should work on
4. DO NOT continue until we agree on the task
```

### Reset Context

If agent is too far gone:
1. Start a new conversation
2. Use the Ralph script: `./scripts/ralph.ps1 -Mode build`
3. Copy the FULL prompt (don't modify it)
4. Verify agent reads IMPLEMENTATION_PLAN.md first

### Document the Issue

Add to IMPLEMENTATION_PLAN.md:

```markdown
## Discovered Issues

- Agent went rogue on [date]: Started working without reading plan
  - What happened: [description]
  - How fixed: [reset/redirected]
  - Prevention: [what to do differently]
```

## Prevention Strategies

### For Users

1. **Always use scripts**: `ralph.ps1` or `ralph.sh` generate correct prompts
2. **Don't paraphrase**: Copy the full prompt exactly
3. **Verify first action**: Agent should read IMPLEMENTATION_PLAN.md first
4. **Interrupt early**: Stop agent at first sign of going off-track
5. **Fresh context**: Start new conversation if context gets polluted

### For Framework Maintainers

1. **Keep AGENTS.md prominent**: Critical instructions at the top
2. **Make PROMPT files explicit**: "STOP" and "DO NOT" sections
3. **Test with multiple AIs**: Verify protocol works universally
4. **Document failures**: Track when/why agents go rogue
5. **Improve clarity**: Update instructions based on failures

## Why This Works

This approach is **universal** because:
- No IDE dependencies (works in ChatGPT web, Claude, Kiro, terminal)
- No special features required (just markdown files)
- Human-readable (user can verify agent follows protocol)
- Self-documenting (instructions are explicit)
- Fail-safe (user can always interrupt and redirect)

## Limitations

This approach **cannot**:
- Force agents to follow protocol (they can still ignore it)
- Prevent all mistakes (agents can misunderstand)
- Work without user vigilance (user must verify)
- Automate enforcement (no hooks or automation)

But it **can**:
- Make protocol obvious and hard to miss
- Give users clear intervention points
- Work in any environment with any AI
- Scale to teams and different workflows

## Testing Protocol Compliance

To verify an agent follows the protocol:

1. **Start fresh conversation**
2. **Run**: `./scripts/ralph.ps1 -Mode build`
3. **Copy full prompt** to agent
4. **Verify first action**: Agent should read IMPLEMENTATION_PLAN.md
5. **Check task selection**: Agent should pick task from plan, not invent one
6. **Monitor updates**: Agent should update IMPLEMENTATION_PLAN.md after task

If agent fails any step, use "Immediate Action" above.

## Future Improvements

Potential enhancements (while staying universal):

1. **Validation script**: Check that IMPLEMENTATION_PLAN.md was updated
2. **Prompt templates**: More explicit "STOP/GO" decision points
3. **Checklist format**: Agent must confirm each step before proceeding
4. **Example sessions**: Show correct vs incorrect agent behavior
5. **Quick reference**: One-page "agent discipline" reminder

## Related Documents

- `.gsd/protocols/ralph-loop.md` - Complete Ralph Loop specification
- `PROMPT_build.md` - Build mode prompt template
- `PROMPT_plan.md` - Plan mode prompt template
- `AGENTS.md` - Operational procedures for agents
- `IMPLEMENTATION_PLAN.md` - Task tracking and state
